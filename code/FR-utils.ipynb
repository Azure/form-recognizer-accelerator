{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062cd3e4",
   "metadata": {},
   "source": [
    "# This file has Form Recognizer Model trainign and Inferencing code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e790e5a",
   "metadata": {},
   "source": [
    "#### Read configuration file and get endpoint, key of the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Python Form Recognizer Labeled Async Train #############\n",
    "import json\n",
    "import time\n",
    "from requests import get, post\n",
    "\n",
    "#read form recognizer service parameters\n",
    "with open('config.json','r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "# Endpoint URL\n",
    "endpoint = config['endpoint']\n",
    "post_url = endpoint + r\"/formrecognizer/v2.1/custom/models\"\n",
    "apim_key = config['apim-key']\n",
    "filetype = 'application/json'\n",
    "\n",
    "\n",
    "headers = {\n",
    "    # Request headers\n",
    "    'Content-Type': filetype,\n",
    "    'Ocp-Apim-Subscription-Key': apim_key,\n",
    "}\n",
    "\n",
    "body = {\n",
    "    \"source\": \"\",\n",
    "    \"sourceFilter\": {\n",
    "        \"prefix\": \"\",\n",
    "        \"includeSubFolders\": False\n",
    "    },\n",
    "    \"useLabelFile\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f111694c",
   "metadata": {},
   "source": [
    "# Unsupervised training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f43e3e",
   "metadata": {},
   "source": [
    "### Function to train unsupervised Form Recognizer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tries = 60\n",
    "n_try = 0\n",
    "wait_sec = 60\n",
    "\n",
    "\n",
    "def train_fr_model(sas_url, folder_path, model_file):\n",
    "    \n",
    "    body['source'] = sas_url\n",
    "    body['sourceFilter']['prefix'] = folder_path\n",
    "    \n",
    "    # trigger training\n",
    "    try:\n",
    "        resp = post(url = post_url, json = body, headers = headers)\n",
    "        #print(body)\n",
    "        #print(headers)\n",
    "        if resp.status_code != 201:\n",
    "            print(\"Training model failed (%s):\\n%s\" % (resp.status_code, json.dumps(resp.json())))\n",
    "            return\n",
    "        print(\"Training Started:\\n%s\" % resp.headers)\n",
    "        get_url = resp.headers[\"location\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred when triggering training:\\n%s\" % str(e))\n",
    "        quit()\n",
    "        \n",
    "    n_try = 0\n",
    "    #wait for training to complete and save model to json file\n",
    "    while n_try < n_tries:\n",
    "        try:\n",
    "            resp = get(url = get_url, headers = headers)\n",
    "            resp_json = resp.json()\n",
    "            if resp.status_code != 200:\n",
    "                print(\"Model training failed (%s):\\n%s\" % (resp.status_code, json.dumps(resp_json)))\n",
    "                break\n",
    "            model_status = resp_json[\"modelInfo\"][\"status\"]\n",
    "            print(\"Model Status:\", model_status)\n",
    "            if model_status == \"ready\":\n",
    "                #print(\"Training succeeded:\\n%s\" % json.dumps(resp_json))\n",
    "                print(\"Training succeeded:\")\n",
    "                with open(model_file,\"w\") as f:\n",
    "                    json.dump(resp_json, f)\n",
    "                break\n",
    "            if model_status == \"invalid\":\n",
    "                print(\"Training failed. Model is invalid:\\n%s\" % json.dumps(resp_json))\n",
    "                break\n",
    "            # Training still running. Wait and retry.\n",
    "            time.sleep(wait_sec)\n",
    "            n_try += 1\n",
    "        except Exception as e:\n",
    "            msg = \"Model training returned error:\\n%s\" % str(e)\n",
    "            print(msg)\n",
    "            break\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        print(\"Train operation did not complete within the allocated time.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e93ea",
   "metadata": {},
   "source": [
    "# FR Model Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd521e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_infer = {\n",
    "    \"includeTextDetails\": True\n",
    "}\n",
    "\n",
    "headers_infer = {\n",
    "    # Request headers\n",
    "    'Content-Type': 'application/pdf',\n",
    "    'Ocp-Apim-Subscription-Key': apim_key,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1026a9",
   "metadata": {},
   "source": [
    "#### Form Recognizer inferencing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# FR Inference function multithreading\n",
    "#######################################################\n",
    "\n",
    "def fr_mt_inference(files, json_fld, model_id):\n",
    "    \n",
    "    post_url = endpoint + \"formrecognizer/v2.1/custom/models/%s/analyze\" % model_id\n",
    "\n",
    "    \n",
    "    ###################\n",
    "    #send all requests in one go\n",
    "    ###################\n",
    "    session = requests.Session()\n",
    "    url_list=[]\n",
    "    for fl in files:\n",
    "        \n",
    "        #read file\n",
    "        fname = os.path.basename(fl)\n",
    "        #print(\"working on file: %s, %s\" %(fl, datetime.datetime.now()))\n",
    "        with open(fl, \"rb\") as f:\n",
    "            data_bytes = f.read()\n",
    "            \n",
    "        #set variables to default values\n",
    "        get_url = None\n",
    "        #st_time = datetime.datetime.now()\n",
    "        st_time = datetime.now()\n",
    "        gap_between_requests = 1 #in seconds\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            #send post request (wait and send if overlaoded)\n",
    "            post_success = 0\n",
    "            while post_success == 0:\n",
    "                resp = session.post(url = post_url, data = data_bytes, headers = headers_infer, params = params_infer)\n",
    "                if resp.status_code != 429:\n",
    "                    break\n",
    "                time.sleep(1)    \n",
    "                \n",
    "            #print(fl, resp.status_code)\n",
    "                    \n",
    "            if resp.status_code != 202:\n",
    "                print(\"POST analyze failed:\\n%s\" % json.dumps(resp.json()))\n",
    "\n",
    "            #print(\"POST analyze succeeded:\\n%s\" % resp.headers)\n",
    "            #print(\"POST analyze succeeded for %s \\n\" % fl)\n",
    "            get_url = resp.headers[\"operation-location\"]\n",
    "        except Exception as e:\n",
    "            print(\"POST analyze failed 1:\\n%s\" % str(e))\n",
    "        \n",
    "        url_list.append((fl, fname, get_url))\n",
    "        end_time = datetime.now()\n",
    "        #end_time = datetime.datetime.now()\n",
    "        delta = end_time - st_time\n",
    "        delta = delta.total_seconds()\n",
    "        if delta < gap_between_requests:\n",
    "            time.sleep(gap_between_requests - delta)\n",
    "\n",
    "    ####################################\n",
    "    # get all responses in one go\n",
    "    ####################################\n",
    "    n_tries = 15\n",
    "    wait_sec = 15\n",
    "\n",
    "    for cnt in range(n_tries):\n",
    "        \n",
    "        #get results of requests sent\n",
    "        completed = []\n",
    "        for i in range(len(url_list)):\n",
    "\n",
    "            fl, fname, get_url = url_list[i]\n",
    "            if get_url is not None:\n",
    "\n",
    "                try:\n",
    "                    resp = session.get(url = get_url, headers = {\"Ocp-Apim-Subscription-Key\": apim_key})\n",
    "                    resp_json = resp.json()\n",
    "\n",
    "                    if resp.status_code != 200:\n",
    "                        print(\"GET analyze results failed:%s \\n%s\" % fl, json.dumps(resp_json))\n",
    "                        break\n",
    "\n",
    "                    status = resp_json[\"status\"]\n",
    "                    if status == \"succeeded\":\n",
    "                        print(\"Analysis succeeded for %s:\\n\" % fl)\n",
    "                        with open(os.path.join(json_fld,fname.replace('.pdf','.json')), 'w') as outfile:\n",
    "                            json.dump(resp_json, outfile)\n",
    "\n",
    "                        completed.append(i)\n",
    "\n",
    "                    if status == \"failed\":\n",
    "                        print(\"Analysis failed:%s \\n%s\" % fl, json.dumps(resp_json))\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    msg = \"GET analyze results failed 2:\\n%s\" % str(e)\n",
    "                    print(msg)\n",
    "                    break\n",
    "\n",
    "        # remove files where\n",
    "        completed.sort(reverse=True)\n",
    "        for i in completed:\n",
    "            url_list.pop(i)\n",
    "\n",
    "        print(\"iteration\",cnt,\"complete. Still\",len(url_list), \" to infer\")\n",
    "        if len(url_list) == 0:\n",
    "            break\n",
    "            \n",
    "        time.sleep(wait_sec)\n",
    "        \n",
    "    ####################################\n",
    "    # retun files not inferred\n",
    "    ####################################\n",
    "    session.close()\n",
    "    \n",
    "    if len(url_list) == 0:\n",
    "        return(\"All files successfully inferred by FR\")\n",
    "    else:\n",
    "        return(url_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55580da",
   "metadata": {},
   "source": [
    "#### Form Recognizer multi-threading inferencing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form Recognizer inference\n",
    "\n",
    "def fr_model_inference(src_dir, json_dir, model_file, thread_cnt):\n",
    "    \n",
    "    #read model details\n",
    "    with open(model_file,'r') as model_file:\n",
    "        model = json.load(model_file)\n",
    "\n",
    "    if model['modelInfo']['modelId'] != None :\n",
    "        model_id = model['modelInfo']['modelId']\n",
    "        print(\"model id: %s\" % model_id)\n",
    "    else:\n",
    "        print(\"Model details not present, either model training is not performed or the file is missing\")\n",
    "        return\n",
    "    \n",
    "    #Read files and divide into chunks\n",
    "    fls = glob.glob(os.path.join(src_dir, \"*.pdf\"))\n",
    "    print(\"inferencing \", len(fls), \"files with\", thread_cnt, \"thread count\")\n",
    "    fchunk = chunkify(fls, 100)\n",
    "    \n",
    "    for chunk in fchunk:\n",
    "        \n",
    "        fr_threads = min(len(chunk),thread_cnt)\n",
    "\n",
    "        flist = chunkify(chunk, fr_threads)\n",
    "\n",
    "        #Call FR inference \n",
    "        threads= []\n",
    "        with ThreadPoolExecutor(max_workers=thread_cnt) as executor:\n",
    "            for files in flist:\n",
    "                threads.append(executor.submit(fr_mt_inference, files, json_dir, model_id))\n",
    "\n",
    "            for task in as_completed(threads):\n",
    "                print(task.result()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
